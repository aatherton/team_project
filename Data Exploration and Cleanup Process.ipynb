{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Cleanup Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document describes the intricate data collection and cleanup processes we used to build our project on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settling on a data source:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data exploration and cleanup process ended up being much more complex and tedious than we had intended. After we agreed \n",
    "on the topic of Fantasy Football Points by college, we scoured the web and found sources from Kaggle, ESPN and other professional\n",
    "services, Yahoo, free JSON based APIs, and a few third party open sourced projects.\n",
    "\n",
    "Our requirements were:\n",
    "    1. Large set of data spanning across multiple years\n",
    "    2. Aggregated stats by player\n",
    "    3. The college that each player in the NFL attended.\n",
    "    \n",
    "We finally settled on www.sportradar.us, a website that offered free demo API keys with a 1000 call limit per month. Between the 4 of us we thought it would be more than enough calls to get the project done. The services dataset was complex and had several different calls that would contain all the information we needed for our project.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in the data collection process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. We started by seeing what the JSON data looked like, and grabbed a unique identifier for each NFL team. We exported  this list into 'teams_df.csv'.\n",
    "\n",
    "    2. We then looped through each team in teams_df, and retrieved seasonal stats for that team from each year the service had data from (2000-2017). We appended each teams data to a large data frame we called 'all_players.csv'. Here is where we ran into our first problem - the seasonal stats we downloaded did not include colleges for each player.\n",
    "\n",
    "    3. To remedy this, we had to filter the list of 35,000+ rows that contained multiple years of data for each player, and extract a list of unique player IDs. The total unique IDs were ~ 9,000, so we limited the list to offensive players only since they generate the most fantasy points. Surprisingly this was only about 2,600 records. We took this list and made a new call to a different Sportradar service for individual data. We then retrieved each college associated with a players uniqueID, and exported that to 'player_college.csv'. We then used a script that joined the two CSVs together by UniquePlayerID.\n",
    "\n",
    "    4. The next step in our data collection process was to calculate the amount of fantasy points generated by each player. To do this we made a dictionary of each stat category (passing yards, rushing yards, etc..) and assigned a multiplier value for each one. We looped through each row in our offensive_players dataframe, multiplying each column by the appropriate value. This was an awesome script we called 'apply_fantasy.ipynb'. \n",
    "    \n",
    "    5. To make our job in analyzing the data a bit easier, we also went through each line in a loop, and added a new column that totaled all the points for each player for that year.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we completed the steps above, we were left with a complete dataset that had all of the information we needed to \n",
    "begin analyzing the data."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
